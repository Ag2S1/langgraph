{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a1aae78-88a6-4133-b905-7e46c8e3772f",
   "metadata": {},
   "source": [
    "# Introduction to LangGraph\n",
    "\n",
    "In this tutorial, we'll build a customer support chatbot. We'll start with a simple model and gradually add more functionality, introducing key LangGraph concepts along the way. By the end, you will have built a chat bot that can:\n",
    "\n",
    "- Answer common questions by searching a knowledge base\n",
    "- Route complex queries to a human agent for review\n",
    "- Maintain conversation state across sessions\n",
    "\n",
    "Through the process, we will learn key LangGraph concepts like **graph** construction, nodes + edges, human-in-the-loop workflows, memory checkpointing, and more!\n",
    "\n",
    "## Setup\n",
    "\n",
    "First, install the required packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f11d631-8679-4f28-822f-cdf1f2ddc21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "%pip install -U langgraph langsmith\n",
    "\n",
    "# Used for this tutorial; not a requirement for LangGraph\n",
    "%pip install -U langchain langchain_anthropic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6d1e870-1bc0-4d44-86c0-96681ccf6113",
   "metadata": {},
   "source": [
    "Next, set your API keys:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "705d4020-6ee8-44cc-b1a5-8c34e7172fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "\n",
    "def _set_env(var: str):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
    "\n",
    "\n",
    "_set_env(\"ANTHROPIC_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a98c72cf-33f9-4a37-9634-6c93a7c28815",
   "metadata": {},
   "source": [
    "(Encouraged) [LangSmith](https://smith.langchain.com/) makes it a lot easier to see what's going on \"under the hood.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13cba9af-0572-41df-92f8-d6f56d5b5322",
   "metadata": {},
   "outputs": [],
   "source": [
    "_set_env(\"LANGSMITH_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"LangGraph Tutorial\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef7bcad1-1274-4b7c-a2e9-365180ef3a31",
   "metadata": {},
   "source": [
    "## Part 1: Build a Basic Chatbot\n",
    "\n",
    "We'll first create a simple chatbot using LangGraph. This chatbot will respond directly to user messages. Though simple, it will illustrate the core concepts of building with LangGraph. By the end of this section, you will have a built rudimentary chatbot.\n",
    "\n",
    "Start by creating a `StateGraph`. A `StateGraph` object defines the structure of our chatbot as a \"state machine\". We'll add `nodes` to represent the llm and functions our chatbot can call and `edges` to specify how the bot should transition between these functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e58df974-7579-4f25-9d91-66389b94eba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.graph import StateGraph\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    # Messages have the type \"list\". The `add_messages` function\n",
    "    # in the annotation defines how this state key should be updated\n",
    "    # (in this case, it appends messages to the list, rather than overwriting them)\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "\n",
    "graph_builder = StateGraph(State)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4137feed-746e-4c72-a34a-f7a699ad5dcf",
   "metadata": {},
   "source": [
    "**Notice** that we've initialized our `graph_builder` with a `State`. The `State` tells the graph two things:\n",
    "\n",
    "1. Every `node` will receive the current `State` as input and return a value that updates the state.\n",
    "2. `messages` will be _appended_ to the current list, rather than directly overwritten. This is communicated via the prebuilt `add_messages` function in the `Annotated` syntax.\n",
    "\n",
    "Next, add a \"`chatbot`\" node. Nodes represent units of work. They are typically regular python functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc8c9137-8261-42ea-8e83-3590981d23e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_anthropic import ChatAnthropic\n",
    "\n",
    "llm = ChatAnthropic(model=\"claude-3-haiku-20240307\")\n",
    "\n",
    "\n",
    "def chatbot(state: State):\n",
    "    return {\"messages\": [llm.invoke(state[\"messages\"])]}\n",
    "\n",
    "\n",
    "# The first argument is the unique node name\n",
    "# The second argument is the function or object that will be called whenever\n",
    "# the node is used.\n",
    "graph_builder.add_node(\"chatbot\", chatbot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6c1dcd9-fb86-4649-81b4-ff6ce20a2e46",
   "metadata": {},
   "source": [
    "**Notice** that our chatbot node receives an instance of the `State` defined above. It returns an update to the `messages` key.\n",
    "\n",
    "Next, add an `entry` point. This tells our graph **where to start its work** each time we run it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e331e10d-ebcf-4144-9bd3-999b4d656dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_builder.set_entry_point(\"chatbot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0499c318-d1e6-46fa-a652-8f9e65313355",
   "metadata": {},
   "source": [
    "Similarly, set a `finish` point. This instructs the graph **\"any time this node is run, you can exit.\"**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "075f0929-3591-4852-b2d3-eaadde40662d",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_builder.set_finish_point(\"chatbot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a9b88c-2c53-4d95-8eb1-d544a8946f65",
   "metadata": {},
   "source": [
    "Finally, we'll want to be able to run our graph. To do so, call \"`compile()`\" on the graph builder. This creates a \"`CompiledGraph`\" we can use invoke on our state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb67a01-cf5c-4625-8c07-6e8c0af50fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a98097a3-a126-4081-b21e-697ec1185fff",
   "metadata": {},
   "source": [
    "Now let's run the chatbot!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7afb4c9a-7404-4e92-9945-36f372015f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    user_input = input(\"User: \")\n",
    "    if user_input.lower() in [\"quit\", \"exit\", \"q\"]:\n",
    "        print(\"Goodbye!\")\n",
    "        break\n",
    "    for event in graph.stream({\"messages\": (\"user\", user_input)}):\n",
    "        for value in event.values():\n",
    "            print(\"Assistant:\", value[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e1cdb5-869a-41ea-9dab-e28cfc524499",
   "metadata": {},
   "source": [
    "**Notice** that our chat bot lacks access to any up-to-date information to help answer questions. It also lacks memory. Fear not! We will add this all below :)\n",
    "\n",
    "**Congrats!** You've built a simple chatbot using LangGraph. This \"graph\" has a single `node` with no real edges.\n",
    "\n",
    "You can visualize the graph using the `get_graph` and one of the `draw_ascii` or `draw_png` methods (though `draw_png` comes with some other dependencies)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "07e2d8fc-349f-4bdc-bb7e-92481703ad39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "except:\n",
    "    # This requires some extra dependencies and is optional\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dedf5c7-3052-4957-8117-84a1a87e1f8d",
   "metadata": {},
   "source": [
    "Below is the full code for this section for your reference:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e014741f-cfad-4045-b6fa-ebd74ae93a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.graph import StateGraph\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "\n",
    "graph_builder = StateGraph(State)\n",
    "\n",
    "\n",
    "llm = ChatAnthropic(model=\"claude-3-haiku-20240307\")\n",
    "\n",
    "\n",
    "def chatbot(state: State):\n",
    "    return {\"messages\": [llm.invoke(state[\"messages\"])]}\n",
    "\n",
    "\n",
    "# The first argument is the unique node name\n",
    "# The second argument is the function or object that will be called whenever\n",
    "# the node is used.\n",
    "graph_builder.add_node(\"chatbot\", chatbot)\n",
    "graph_builder.set_entry_point(\"chatbot\")\n",
    "graph_builder.set_finish_point(\"chatbot\")\n",
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f22c5d4a-3134-413c-81fe-dd9752fbeb66",
   "metadata": {},
   "source": [
    "## Part 2: Enhancing the Chatbot with Tools\n",
    "\n",
    "Our simple chatbot above can engage in conversation, but it may encounter questions that require up-to-date information to helpfully respond. This is where tools come in. Tools are sany function you define that allow our chatbot to take actions and access external knowledge sources, such as databases or search engines.\n",
    "\n",
    "In this section, we'll enhance our chatbot with a web search tool. When the chatbot receives a question it can't answer with its current knowledge, it can query a search engine and use the results to formulate a response. This will make our chatbot more versatile and able to handle a wider range of user queries.\n",
    "\n",
    "We'll use the Tavily Search in this example. When building your own chat bot, you can include your own retriever.\n",
    "\n",
    "#### Requirements\n",
    "\n",
    "Before we start, make sure you have the necessary packages installed and API keys set up:\n",
    "\n",
    "First, install the requirements to use the [Tavily Search Engine](https://python.langchain.com/docs/integrations/tools/tavily_search/), and set your [TAVILY_API_KEY](https://tavily.com/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7451151f-41fc-4af0-9359-024ae51b7225",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "%pip install -U tavily-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c52923c-5665-4f8c-a1ba-9799e369c49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "_set_env(\"TAVILY_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "591ce9ba-c431-4165-b815-25c944ef7cdb",
   "metadata": {},
   "source": [
    "Next, define the tool:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c8978e-c07d-4dd0-a97b-0ce3a723eea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "tool = TavilySearchResults(max_results=2)\n",
    "tools = [tool]\n",
    "tool.invoke(\"What's a 'node' in LangGraph?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f503f02-d23d-42e8-9b5d-eb2681b242f4",
   "metadata": {},
   "source": [
    "The results are page summaries our chat bot can use to answer questions.\n",
    "\n",
    "\n",
    "Next, we'll start defining our graph. The following is all **the same as in Part 1**, except we have added `bind_tools` on our LLM. This lets the LLM know the correct JSON format to use if it wants to use our search engine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "dc5af88b-47d2-43bf-9a2c-6c07506b1732",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.graph import StateGraph\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "\n",
    "graph_builder = StateGraph(State)\n",
    "\n",
    "\n",
    "llm = ChatAnthropic(model=\"claude-3-haiku-20240307\")\n",
    "# Tell the LLM which tools it can call\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "\n",
    "def chatbot(state: State):\n",
    "    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\n",
    "\n",
    "\n",
    "graph_builder.add_node(\"chatbot\", chatbot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e84cfc-b1b2-48e3-8550-152a408c3926",
   "metadata": {},
   "source": [
    "Now we'll add the tools to a new node. The `ToolNode` is a helper class in LangGraph that `invoke`'s the selected tools whenever the LLM responds with 1 or more tool calls. It relies on `tool_calling` support, which is available in Anthropic, OpenAI, Google Gemini, and a number of other LLM providers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f1fc14-cd91-4cd4-9f2e-1d007f8beafc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import ToolNode\n",
    "\n",
    "tool_node = ToolNode(tools=[tool])\n",
    "graph_builder.add_node(\"action\", tool_node)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b049afc4-7757-40ba-8e00-589d378e816d",
   "metadata": {},
   "source": [
    "With the tool node added, we can define the `conditional_edges`. \n",
    "\n",
    "**Conditional edges** are functions that contain \"if\" statements that return the next node or nodes to execute. The functions are provided the current graph state and return a string or list of strings depending on what node to call next.\n",
    "\n",
    "Below, call `add_conditional_edges` to route from the `chatbot` node to either the `action` or \"end\" using the prebuilt `tools_condition` function. Then create an edge from  the action/tools node _back to_ the chat bot to let it observe the response from our search engine and decide whether it has enough information to answer the user's question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d662df94-66ac-4c6c-92f0-4c93620f1c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import tools_condition\n",
    "\n",
    "# The `tools_condition` function returns \"action\" if the chatbot asks to use a tool, and \"__end__\" if\n",
    "# it is fine directly responding. This conditional routing defines the main agent loop.\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"chatbot\",\n",
    "    tools_condition,\n",
    "    # The following dictionary lets you tell the graph to interpret the condition's outputs as a specific node\n",
    "    # It defaults to the identity function, but if you\n",
    "    # want to use a node named something else apart from \"action\",\n",
    "    # You can update the value of the dictionary to something else\n",
    "    # e.g., \"action\": \"my_tools\"\n",
    "    {\"action\": \"action\", \"__end__\": \"__end__\"},\n",
    ")\n",
    "# Any time a tool is called, we return to the chatbot to decide the next step\n",
    "graph_builder.add_edge(\"action\", \"chatbot\")\n",
    "graph_builder.set_entry_point(\"chatbot\")\n",
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2aa67c2-dd1b-4bf2-8c64-eea44296d15f",
   "metadata": {},
   "source": [
    "**Notice** that conditional edges start from a single node. This tells the graph \"any time 'chatbot' runs, either go to 'action' if it calls a tool, or end the loop if it responds directly. \n",
    "\n",
    "Since the prebuilt `tools_condition` returns the \"`__end__`\" string if no tool calls are made, we don't have to explicitly set the `finish_point` this time (our graph already has a way to finish).\n",
    "\n",
    "Let's visualize the graph we've built. The following function has some additional dependencies to run that are unimportant for this tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "8b49509c-9d97-457c-a76a-c495fb30ccbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "try:\n",
    "    display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "except:\n",
    "    # This requires some extra dependencies and is optional\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c59593ef-5073-4279-931e-828dae971f23",
   "metadata": {},
   "source": [
    "Now we can ask the bot questions about current information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "051dc374-67cc-4371-9dd1-221e07593148",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import BaseMessage\n",
    "\n",
    "while True:\n",
    "    user_input = input(\"User: \")\n",
    "    if user_input.lower() in [\"quit\", \"exit\", \"q\"]:\n",
    "        print(\"Goodbye!\")\n",
    "        break\n",
    "    for event in graph.stream({\"messages\": [(\"user\", user_input)]}):\n",
    "        for value in event.values():\n",
    "            if isinstance(value[\"messages\"][-1], BaseMessage):\n",
    "                print(\"Assistant:\", value[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89da9e85-2e5d-49c2-8cbd-572cbdb89135",
   "metadata": {},
   "source": [
    "**Congrats!** You've created a conversational agent in langgraph that can use a search engine to retrieve updated information when needed.\n",
    "\n",
    "The full code for the graph we've created in this section is reproduced below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8755d551-160e-4f8f-afac-0e4e07ca79ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated, Union\n",
    "\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_core.messages import BaseMessage\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.graph import StateGraph\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt import ToolNode\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "\n",
    "graph_builder = StateGraph(State)\n",
    "\n",
    "\n",
    "tool = TavilySearchResults(max_results=2)\n",
    "tools = [tool]\n",
    "llm = ChatAnthropic(model=\"claude-3-haiku-20240307\")\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "\n",
    "def chatbot(state: State):\n",
    "    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\n",
    "\n",
    "\n",
    "graph_builder.add_node(\"chatbot\", chatbot)\n",
    "\n",
    "tool_node = ToolNode(tools=[tool])\n",
    "graph_builder.add_node(\"action\", tool_node)\n",
    "\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"chatbot\",\n",
    "    tools_condition,\n",
    "    {\"action\": \"action\", \"__end__\": \"__end__\"},\n",
    ")\n",
    "# Any time a tool is called, we return to the chatbot to decide the next step\n",
    "graph_builder.add_edge(\"action\", \"chatbot\")\n",
    "graph_builder.set_entry_point(\"chatbot\")\n",
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae45f2aa-396f-4f3f-848b-7750611617f8",
   "metadata": {},
   "source": [
    "## Part 3: Adding Memory to the Chatbot\n",
    "\n",
    "Our chatbot can now use tools to answer user questions, but it doesn't remember the context of previous interactions. This limits its ability to have coherent, multi-turn conversations.\n",
    "\n",
    "LangGraph solves this problem by allowing you to persist the full graph state for each step in the graph's execution. This is done through a configurable `checkpointer`. \n",
    "\n",
    "If you provide a `checkpointer` when compiling the graph and a `thread_id` when calling your graph, LangGraph automatically saves the state after each transition. In subsequent interactions with the same `thread_id`, the saved state is loaded, allowing the chatbot to pick up where it left off. \n",
    "\n",
    "We will see later that **checkpointing** is _much_ more powerful than simple chat memory - it lets you save and resume complex state at any time for error recovery, human-in-the-loop workflows, time travel interactions, and more. But we'll save that for later on in the tutorial. For now, let's focus on using checkpointing to enable multi-turn conversations.\n",
    "\n",
    "To get started, we'll first create a `checkpointer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6baafdf6-6803-4305-9381-9dc970468a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "\n",
    "memory = SqliteSaver.from_conn_string(\":memory:\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d3d11a-1b42-4cbb-8e11-2a4294263d90",
   "metadata": {},
   "source": [
    "Notice that we've specified `:memory` as the Sqlite DB path. This is convenient for our tutorial (it saves it all in-memory), but in a real application, you would change this to an existing DB and/or use one of the other checkpointer classes.\n",
    "\n",
    "Next define the graph. The following is all copied from Part 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e6a51f1e-00de-4701-8931-de8cf19294ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated, Union\n",
    "\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_core.messages import BaseMessage\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.graph import StateGraph\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt import ToolNode\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "\n",
    "graph_builder = StateGraph(State)\n",
    "\n",
    "\n",
    "tool = TavilySearchResults(max_results=2)\n",
    "tools = [tool]\n",
    "llm = ChatAnthropic(model=\"claude-3-haiku-20240307\")\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "\n",
    "def chatbot(state: State):\n",
    "    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\n",
    "\n",
    "\n",
    "graph_builder.add_node(\"chatbot\", chatbot)\n",
    "\n",
    "tool_node = ToolNode(tools=[tool])\n",
    "graph_builder.add_node(\"action\", tool_node)\n",
    "\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"chatbot\",\n",
    "    tools_condition,\n",
    "    {\"action\": \"action\", \"__end__\": \"__end__\"},\n",
    ")\n",
    "# Any time a tool is called, we return to the chatbot to decide the next step\n",
    "graph_builder.add_edge(\"action\", \"chatbot\")\n",
    "graph_builder.set_entry_point(\"chatbot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a292dfe-764f-4561-90aa-71317d679d3e",
   "metadata": {},
   "source": [
    "Finally, compile the graph with the provided checkpointer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a06548bf-81fa-4436-b4c1-f68601fb4187",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = graph_builder.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c8265ef-e5b4-4c32-9856-5572b5652142",
   "metadata": {},
   "source": [
    "Now you can interact with your bot! First, pick a thread to use as the key for this conversation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "be7b5abb-04ef-4d53-83d1-d4d3139cc43a",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"1\"}}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0b1a5ee-7fa2-475c-a9db-749694b90ba9",
   "metadata": {},
   "source": [
    "Next, call your chat bot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dba1b168-f8e0-496d-9bd6-37198fb4776e",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input = \"Hi there! My name is Will.\"\n",
    "\n",
    "# The config is the **second positional argument** to stream() or invoke()!\n",
    "events = graph.stream({\"messages\": [(\"user\", user_input)]}, config)\n",
    "for event in events:\n",
    "    for value in event.values():\n",
    "        if isinstance(value, BaseMessage):\n",
    "            print(\"Assistant:\", value.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33c6b470-5082-4c3e-b732-34de47c88735",
   "metadata": {},
   "source": [
    "**Note:** The config was provided as the **second positional argument** when calling our graph. It importantly is _not_ nested within the graph inputs (`{'messages': []}`).\n",
    "\n",
    "Let's ask a followup: see if it remembers your name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f5447778-53d7-47f3-801b-f47bcf2185a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant: Yes, I remember your name is Will. It's nice to meet you!\n"
     ]
    }
   ],
   "source": [
    "user_input = \"Remember my name?\"\n",
    "\n",
    "# The config is the **second positional argument** to stream() or invoke()!\n",
    "events = graph.stream({\"messages\": [(\"user\", user_input)]}, config)\n",
    "for event in events:\n",
    "    for value in event.values():\n",
    "        if isinstance(value[\"messages\"][-1], BaseMessage):\n",
    "            print(\"Assistant:\", value[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33be4cd8-f96f-4949-9d1f-48054502e5d0",
   "metadata": {},
   "source": [
    "**Notice** that we are't the memory using an external list: it's all handled by the checkpointer!  Don't believe me? Try this using a different config."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4527cf9a-b191-4bde-858a-e33a74a48c55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant: I'm afraid I don't actually have the capability to remember your name. As an AI assistant, I don't have a persistent memory of individual users or their names. I respond based on the current conversation without retaining details about previous interactions. Could you please restate your request or provide more context so I can try to assist you further?\n"
     ]
    }
   ],
   "source": [
    "# The only difference is we change the `thread_id` here to \"2\" instead of \"1\"\n",
    "events = graph.stream(\n",
    "    {\"messages\": [(\"user\", user_input)]}, {\"configurable\": {\"thread_id\": \"2\"}}\n",
    ")\n",
    "for event in events:\n",
    "    for value in event.values():\n",
    "        if isinstance(value[\"messages\"][-1], BaseMessage):\n",
    "            print(\"Assistant:\", value[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eeccbf0-ed74-4838-a7e9-31910d82b0b2",
   "metadata": {},
   "source": [
    "**Notice** that the **only** change we've made is to modify the `thread_id` in the config. You can inspect a graph's `state` for a given config at any time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0be77c25-1423-4f2d-9b2d-28530cc761a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StateSnapshot(values={'messages': [HumanMessage(content='Hi there! My name is Will.', id='da4184e5-6f54-46ac-9ff6-e0abb6067e0c'), AIMessage(content=\"It's nice to meet you, Will! I'm an AI assistant created by Anthropic. I'm here to help with any questions or tasks you may have. Please let me know if there is anything I can assist you with.\", response_metadata={'id': 'msg_01QW6mTodtPNV68zpK3USpzu', 'model': 'claude-3-haiku-20240307', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 375, 'output_tokens': 51}}, id='run-f89d85bc-17db-44e7-a239-8c2a383f0452-0'), HumanMessage(content='Remember my name?', id='ecee737f-76e6-4d6d-b7c1-f77e669c4bbd'), AIMessage(content=\"Yes, I remember your name is Will. It's nice to meet you!\", response_metadata={'id': 'msg_01RUWVuULio9mTbjJqRuzqGy', 'model': 'claude-3-haiku-20240307', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 433, 'output_tokens': 19}}, id='run-8df655aa-0e38-47fa-87a7-c7f7b1262e79-0')]}, next=(), config={'configurable': {'thread_id': '1', 'thread_ts': '2024-04-17T20:49:25.845078+00:00'}}, parent_config=None)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snapshot = graph.get_state(config)\n",
    "snapshot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c106bd09-f155-4e15-9120-c60c834106e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "()"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snapshot.next  # (since the graph ended this turn, `next` is empty. If you fetch a state from within a graph invocation, next tells which node will execute next)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "627f4998-6780-4cce-8f3c-9a5580888e3a",
   "metadata": {},
   "source": [
    "**Congrats!** You've successfully added a **persistant checkpointer** to your graph. This lets you save each step of execution so you can handle **multi-turn conversations**. It also makes your AI applications more robust, since they can recover from and resume any time an error occurs. This is helpful for long-running operations and also opens the door to more powerful human-in-the-loop workflows (up next) and time-travel debugging and exploration (later). \n",
    "\n",
    "LangGraph's checkpointing is done for graph as a whole and can handle **arbitrary states**, meaning it is much more powerful than simple ChatMessageHistory.\n",
    "\n",
    "This section's code is repeated below for you to copy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c50a794-3ae5-484c-8edd-50e0d54da982",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated, Union\n",
    "\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_core.messages import BaseMessage\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "from langgraph.graph import MessageGraph, StateGraph\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt import ToolNode\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "\n",
    "graph_builder = StateGraph(State)\n",
    "\n",
    "\n",
    "tool = TavilySearchResults(max_results=2)\n",
    "tools = [tool]\n",
    "llm = ChatAnthropic(model=\"claude-3-haiku-20240307\")\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "\n",
    "def chatbot(state: State):\n",
    "    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\n",
    "\n",
    "\n",
    "graph_builder.add_node(\"chatbot\", chatbot)\n",
    "\n",
    "tool_node = ToolNode(tools=[tool])\n",
    "graph_builder.add_node(\"action\", tool_node)\n",
    "\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"chatbot\",\n",
    "    tools_condition,\n",
    "    {\"action\": \"action\", \"__end__\": \"__end__\"},\n",
    ")\n",
    "graph_builder.add_edge(\"action\", \"chatbot\")\n",
    "graph_builder.set_entry_point(\"chatbot\")\n",
    "graph = graph_builder.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f1da240-ec9b-441f-9d47-44c6dc85d540",
   "metadata": {},
   "source": [
    "## Part 4: Human-in-the-loop\n",
    "\n",
    "Agents can be unreliable and may need human input to successfully accomplish tasks. Similarly, for some actions, you may want to require human approval before running to ensure that everything is running as intended.\n",
    "\n",
    "LangGraph supports `human-in-the-loop` workflows in a number of ways. In this section, we will use LangGraph's `interrupt_before` functionality to always break the tool node.\n",
    "\n",
    "First, start from our existing code. The following is copied from Part 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5a81608a-373a-4339-b1c6-65b73a92b983",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated, Union\n",
    "\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_core.messages import BaseMessage\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "from langgraph.graph import MessageGraph, StateGraph\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt import ToolNode\n",
    "\n",
    "memory = SqliteSaver.from_conn_string(\":memory:\")\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "\n",
    "graph_builder = StateGraph(State)\n",
    "\n",
    "\n",
    "tool = TavilySearchResults(max_results=2)\n",
    "tools = [tool]\n",
    "llm = ChatAnthropic(model=\"claude-3-haiku-20240307\")\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "\n",
    "def chatbot(state: State):\n",
    "    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\n",
    "\n",
    "\n",
    "graph_builder.add_node(\"chatbot\", chatbot)\n",
    "\n",
    "tool_node = ToolNode(tools=[tool])\n",
    "graph_builder.add_node(\"action\", tool_node)\n",
    "\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"chatbot\",\n",
    "    tools_condition,\n",
    "    {\"action\": \"action\", \"__end__\": \"__end__\"},\n",
    ")\n",
    "graph_builder.add_edge(\"action\", \"chatbot\")\n",
    "graph_builder.set_entry_point(\"chatbot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "813505b2-18c1-46e9-b891-20a34232808b",
   "metadata": {},
   "source": [
    "Now, compile the graph, specifying to `interrupt_before` the `action` node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b0883e32-1a39-4ce9-ae32-bbd66708fd84",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = graph_builder.compile(\n",
    "    checkpointer=memory,\n",
    "    # This is new!\n",
    "    interrupt_before=[\"action\"],\n",
    "    # Note: can also interrupt __after__ actions, if desired.\n",
    "    # interrupt_after=[\"action\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9f318020-ab7e-415b-a5e2-eddec6d9f3a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant: [{'text': 'Okay, let me do some more in-depth research on LangGraph for you.', 'type': 'text'}, {'id': 'toolu_01YWBi2paSf5jDF1wKHfeaVW', 'input': {'query': 'what is langGraph library'}, 'name': 'tavily_search_results_json', 'type': 'tool_use'}]\n"
     ]
    }
   ],
   "source": [
    "user_input = \"I'm learning LangGraph. Could you do some research on it for me?\"\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "# The config is the **second positional argument** to stream() or invoke()!\n",
    "events = graph.stream({\"messages\": [(\"user\", user_input)]}, config)\n",
    "for event in events:\n",
    "    for value in event.values():\n",
    "        if isinstance(value[\"messages\"][-1], BaseMessage):\n",
    "            print(\"Assistant:\", value[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39405637-13b1-40b1-a51e-6d60bf675ff1",
   "metadata": {},
   "source": [
    "Let's inspect the graph state to confirm it worked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9bb7af46-9b4f-4bb1-b8b9-e9ddf7dbc82c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('action',)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snapshot = graph.get_state(config)\n",
    "snapshot.next"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89326046-2b11-4812-8b6d-8780306ec275",
   "metadata": {},
   "source": [
    "**Notice** that unlike last time, the \"next\" node is set to **'action'**. We've interrupted here! Let's check the tool invocation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3facda0a-e6ad-4b28-b627-753ad8c90c15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'tavily_search_results_json',\n",
       "  'args': {'query': 'what is langGraph library'},\n",
       "  'id': 'toolu_01YWBi2paSf5jDF1wKHfeaVW'}]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "existing_message = snapshot.values[\"messages\"][-1]\n",
    "existing_message.tool_calls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a55a4c70-7226-4be0-8562-391f72bc1f2b",
   "metadata": {},
   "source": [
    "This query seems reasonable. Nothing to filter here. The simplest thing the human can do is just let the graph continue executing. Let's do that below.\n",
    "\n",
    "Next, continue the graph! Passing in `None` will just let the graph continue where it left off, without adding anything new to the state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "effb95d9-b7d5-40c5-9253-253d193b23b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant: [{\"url\": \"https://medium.com/@cplog/introduction-to-langgraph-a-beginners-guide-14f9be027141\", \"content\": \"2. LangGraph is a powerful tool for building stateful, multi-actor applications with Large Language Models (LLMs). It extends the LangChain library, allowing you to coordinate multiple chains (or ...\"}, {\"url\": \"https://python.langchain.com/docs/langgraph/\", \"content\": \"LangGraph is a library for building stateful, multi-actor applications with LLMs, built on top of (and intended to be used with) LangChain . It extends the LangChain Expression Language with the ability to coordinate multiple chains (or actors) across multiple steps of computation in a cyclic manner. It is inspired by Pregel and Apache Beam .\"}]\n",
      "Assistant: Based on the additional search results, here's a more detailed overview of what LangGraph is:\n",
      "\n",
      "- LangGraph is a Python library that extends the LangChain framework, allowing developers to build more complex, stateful applications using large language models (LLMs).\n",
      "\n",
      "- The key feature of LangGraph is its ability to coordinate multiple \"actors\" or chains within a single application, enabling cyclic, multi-step computation.\n",
      "\n",
      "- This is achieved by extending the LangChain Expression Language (LCEL) to support this more sophisticated, multi-agent coordination.\n",
      "\n",
      "- LangGraph is inspired by distributed computing frameworks like Pregel and Apache Beam, which enable stateful, graph-based computations across multiple nodes.\n",
      "\n",
      "- Some example use cases for LangGraph include building conversational agents that can maintain context across multiple turns, or knowledge-retrieval systems that can iteratively refine their queries based on previous results.\n",
      "\n",
      "- LangGraph also aims to make the internal workings of LangChain's AgentExecutor more accessible and customizable for developers.\n",
      "\n",
      "Does this help summarize the key capabilities and purpose of the LangGraph library? Let me know if you need any clarification or have additional questions!\n"
     ]
    }
   ],
   "source": [
    "# `None` will append nothing new to the current state, letting it resume as if it had never been interrupted\n",
    "events = graph.stream(None, config)\n",
    "for event in events:\n",
    "    for value in event.values():\n",
    "        if isinstance(value[\"messages\"][-1], BaseMessage):\n",
    "            print(\"Assistant:\", value[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e78a97-474f-4709-b51d-9d5e8323e14c",
   "metadata": {},
   "source": [
    "**Congrats!** You've added an interrupt to permit a human check before any `action` is taken. This lets a human review and even update the graph state before continuing. Since we have already added a **checkpointer**, the graph can be paused **indefinitely** and resumed at any time as if nothing had happened.\n",
    "\n",
    "But what if we the user (or operator) _does_ want to intercede in the graph execution? We will touch on that next.\n",
    "\n",
    "Below is a copy of the code you used in this section. The only difference between this and the previous parts is the addition of the `interrupt_before` argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a7228caf-a5aa-4f68-b775-81ea5402aca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated, Union\n",
    "\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_core.messages import BaseMessage\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "from langgraph.graph import MessageGraph, StateGraph\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt import ToolNode\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "\n",
    "graph_builder = StateGraph(State)\n",
    "\n",
    "\n",
    "tool = TavilySearchResults(max_results=2)\n",
    "tools = [tool]\n",
    "llm = ChatAnthropic(model=\"claude-3-haiku-20240307\")\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "\n",
    "def chatbot(state: State):\n",
    "    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\n",
    "\n",
    "\n",
    "graph_builder.add_node(\"chatbot\", chatbot)\n",
    "\n",
    "tool_node = ToolNode(tools=[tool])\n",
    "graph_builder.add_node(\"action\", tool_node)\n",
    "\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"chatbot\",\n",
    "    tools_condition,\n",
    "    {\"action\": \"action\", \"__end__\": \"__end__\"},\n",
    ")\n",
    "graph_builder.add_edge(\"action\", \"chatbot\")\n",
    "graph_builder.set_entry_point(\"chatbot\")\n",
    "\n",
    "memory = SqliteSaver.from_conn_string(\":memory:\")\n",
    "graph = graph_builder.compile(\n",
    "    checkpointer=memory,\n",
    "    # This is new!\n",
    "    interrupt_before=[\"action\"],\n",
    "    # Note: can also interrupt __after__ actions, if desired.\n",
    "    # interrupt_after=[\"action\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "646d4102-6127-46b3-8c34-a8043d6a811c",
   "metadata": {},
   "source": [
    "## Part 5: Manually Updating the State\n",
    "\n",
    "In the previous section, we showed how to interrupt a graph so that a human could inspect its actions. This lets the human `read` the state, but if they want to change they agent's course, they'll need to have `write` access.\n",
    "\n",
    "Thankfully, LangGraph lets you **manually update state**! You can update state to control the agent's trajectory by modifying its actions (even modifying the past!). This capability is particularly useful when you want to correct the agent's mistakes, explore alternative paths, or guide the agent towards a specific goal.\n",
    "\n",
    "We'll show how to update state below. As before, first, define your graph. We'll re-use the exact same graph as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "faa345c6-38a2-42e8-9035-9cf56f7bb5b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant: [{'text': 'Okay, let me do some more research on LangGraph for you.', 'type': 'text'}, {'id': 'toolu_0177fp6VDJrjsVP62BMMm5kR', 'input': {'query': 'how to use langGraph library'}, 'name': 'tavily_search_results_json', 'type': 'tool_use'}]\n"
     ]
    }
   ],
   "source": [
    "from typing import Annotated, Union\n",
    "\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_core.messages import BaseMessage\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "from langgraph.graph import MessageGraph, StateGraph\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt import ToolNode\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "\n",
    "graph_builder = StateGraph(State)\n",
    "\n",
    "\n",
    "tool = TavilySearchResults(max_results=2)\n",
    "tools = [tool]\n",
    "llm = ChatAnthropic(model=\"claude-3-haiku-20240307\")\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "\n",
    "def chatbot(state: State):\n",
    "    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\n",
    "\n",
    "\n",
    "graph_builder.add_node(\"chatbot\", chatbot)\n",
    "\n",
    "tool_node = ToolNode(tools=[tool])\n",
    "graph_builder.add_node(\"action\", tool_node)\n",
    "\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"chatbot\",\n",
    "    tools_condition,\n",
    "    {\"action\": \"action\", \"__end__\": \"__end__\"},\n",
    ")\n",
    "graph_builder.add_edge(\"action\", \"chatbot\")\n",
    "graph_builder.set_entry_point(\"chatbot\")\n",
    "memory = SqliteSaver.from_conn_string(\":memory:\")\n",
    "graph = graph_builder.compile(\n",
    "    checkpointer=memory,\n",
    "    # This is new!\n",
    "    interrupt_before=[\"action\"],\n",
    "    # Note: can also interrupt __after__ actions, if desired.\n",
    "    # interrupt_after=[\"action\"]\n",
    ")\n",
    "\n",
    "user_input = \"I'm learning LangGraph. Could you do some research on it for me?\"\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "# The config is the **second positional argument** to stream() or invoke()!\n",
    "events = graph.stream({\"messages\": [(\"user\", user_input)]}, config)\n",
    "for event in events:\n",
    "    for value in event.values():\n",
    "        if isinstance(value[\"messages\"][-1], BaseMessage):\n",
    "            print(\"Assistant:\", value[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a6b3bcae-dd04-49da-a4ef-e05634657faf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "[{'text': 'Okay, let me do some more research on LangGraph for you.', 'type': 'text'}, {'id': 'toolu_0177fp6VDJrjsVP62BMMm5kR', 'input': {'query': 'how to use langGraph library'}, 'name': 'tavily_search_results_json', 'type': 'tool_use'}]\n"
     ]
    }
   ],
   "source": [
    "snapshot = graph.get_state(config)\n",
    "existing_message = snapshot.values[\"messages\"][-1]\n",
    "existing_message.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bf55a26-8c12-477a-9e83-5011d36ac4ee",
   "metadata": {},
   "source": [
    "So far, all of this is an exact repeat of the previous section. The LLM just requested to use the search engine tool and our graph was interrupted. If we proceed as before, the tool will be called to search the web.\n",
    "\n",
    "But what if the user wants to intercede? What if we think the chat bot doesn't need to use the tool? \n",
    "\n",
    "Let's directly provide the correct response!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6a44bedc-ea91-4c22-976c-98b3d5a5e4a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "LangGraph is a library for building stateful, multi-actor applications with LLMs.\n",
      "\n",
      "\n",
      "Last 2 messages;\n",
      "[AIMessage(content=[{'text': 'Okay, let me do some more research on LangGraph for you.', 'type': 'text'}, {'id': 'toolu_0177fp6VDJrjsVP62BMMm5kR', 'input': {'query': 'how to use langGraph library'}, 'name': 'tavily_search_results_json', 'type': 'tool_use'}], response_metadata={'id': 'msg_01KttStmqGq1aBU27nLLQmNQ', 'model': 'claude-3-haiku-20240307', 'stop_reason': 'tool_use', 'stop_sequence': None, 'usage': {'input_tokens': 1698, 'output_tokens': 80}}, id='run-82ed92d8-3010-442a-bb87-2a23210589ba-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'how to use langGraph library'}, 'id': 'toolu_0177fp6VDJrjsVP62BMMm5kR'}]), AIMessage(content='LangGraph is a library for building stateful, multi-actor applications with LLMs.', id='ac2edd5f-c5c5-4ea1-b366-903f8a55d240')]\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage, ToolMessage\n",
    "\n",
    "new_message = AIMessage(\n",
    "    content=\"LangGraph is a library for building stateful, multi-actor applications with LLMs.\"\n",
    ")\n",
    "\n",
    "new_message.pretty_print()\n",
    "graph.update_state(\n",
    "    # Which state to update\n",
    "    config,\n",
    "    # The updated values to provide. The messages in our `State` are \"append-only\", meaning this will be appended\n",
    "    # to the existing state. We will review how to update existing messages in the next section!\n",
    "    {\"messages\": [new_message]},\n",
    ")\n",
    "\n",
    "print(\"\\n\\nLast 2 messages;\")\n",
    "print(graph.get_state(config).values[\"messages\"][-2:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "584de971-6b10-4931-986e-cc35f7adbb3d",
   "metadata": {},
   "source": [
    "Now the graph is complete, since we've provided the final response message!\n",
    "\n",
    "**Notice** that our new messages is _appended_ to the messages already in the state. Remember how we defined our `State`?\n",
    "\n",
    "```python\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "```\n",
    "\n",
    "Since we used the pre-built `add_messages` to always append values to the existing list, the new messages added using `update_state` were added in the same way!\n",
    "\n",
    "In fact, the `update_state` function operates as if it were one of the nodes in your graph! By default, the update operation uses the node that was last exectued, but you can also manually specify it below. Let's add an update that is meant to come from the \"chatbot\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d16d95c3-b465-42ac-8015-26b669d45d1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'configurable': {'thread_id': '1',\n",
       "  'thread_ts': '2024-04-17T21:38:57.816482+00:00'}}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.update_state(\n",
    "    config,\n",
    "    {\"messages\": [AIMessage(content=\"I'm an AI expert!\")]},\n",
    "    # Which node for this function to act as. It will automatically continue\n",
    "    # processing as if this node just ran.\n",
    "    as_node=\"chatbot\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d420e813-a8c7-415d-ab31-5298d42491e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[AIMessage(content=[{'text': 'Okay, let me do some more research on LangGraph for you.', 'type': 'text'}, {'id': 'toolu_0177fp6VDJrjsVP62BMMm5kR', 'input': {'query': 'how to use langGraph library'}, 'name': 'tavily_search_results_json', 'type': 'tool_use'}], response_metadata={'id': 'msg_01KttStmqGq1aBU27nLLQmNQ', 'model': 'claude-3-haiku-20240307', 'stop_reason': 'tool_use', 'stop_sequence': None, 'usage': {'input_tokens': 1698, 'output_tokens': 80}}, id='run-82ed92d8-3010-442a-bb87-2a23210589ba-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'how to use langGraph library'}, 'id': 'toolu_0177fp6VDJrjsVP62BMMm5kR'}]), AIMessage(content='LangGraph is a library for building stateful, multi-actor applications with LLMs.', id='ac2edd5f-c5c5-4ea1-b366-903f8a55d240'), AIMessage(content=\"I'm an AI expert!\", id='991ffe4b-fefa-4793-bcc4-9a9c2db87b17')]\n",
      "()\n"
     ]
    }
   ],
   "source": [
    "snapshot = graph.get_state(config)\n",
    "print(snapshot.values[\"messages\"][-3:])\n",
    "print(snapshot.next)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "380222f4-65fa-4962-afe6-6a715fadb2de",
   "metadata": {},
   "source": [
    "**Notice**: that we've continued to add AI messages to the state. Since we are acting as the `chatbot` and responding with an AIMessage that doesn't contain `tool_calls`, the graph knows that it has entered a finished state (`next` is empty).\n",
    "\n",
    "#### What if you want to **overwrite** existing messages? \n",
    "\n",
    "We can do this by adding a message with an `id` that matches one of the messages in the existing state list. Within the `add_messages` function we used to annotate our graph's `State`, it looks at any message IDs in the state update. If the ID matches a message in the existing state, `add_messages` overwrites the existing message with the new content.\n",
    "\n",
    "As an example, let's update the tool invocation to make sure we get good results from our search engine! First, start a new thread:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "9fc99c7e-b61d-4aec-9c62-042798185ec3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant: [{'text': 'Okay, let me do some more in-depth research on LangGraph for you.', 'type': 'text'}, {'id': 'toolu_01KmbJB42aWwSpHHmH64wJ2h', 'input': {'query': 'what is langGraph'}, 'name': 'tavily_search_results_json', 'type': 'tool_use'}]\n"
     ]
    }
   ],
   "source": [
    "user_input = \"I'm learning LangGraph. Could you do some research on it for me?\"\n",
    "config = {\"configurable\": {\"thread_id\": \"2\"}}  # we'll use thread_id = 2 here\n",
    "events = graph.stream({\"messages\": [(\"user\", user_input)]}, config)\n",
    "for event in events:\n",
    "    for value in event.values():\n",
    "        if isinstance(value[\"messages\"][-1], BaseMessage):\n",
    "            print(\"Assistant:\", value[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b019fc6-7826-4291-9178-6cecb5d7b3d0",
   "metadata": {},
   "source": [
    "**Next,** let's update the tool invocation for our agent. Maybe we want to search for human-in-the-loop workflows in particular."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "7215533a-b7e2-4b2d-bc1d-5122b1d06b8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original\n",
      "{'name': 'tavily_search_results_json', 'args': {'query': 'what is langGraph'}, 'id': 'toolu_01KmbJB42aWwSpHHmH64wJ2h'}\n",
      "Updated\n",
      "{'name': 'tavily_search_results_json', 'args': {'query': 'LangGraph human-in-the-loop workflow'}, 'id': 'toolu_01KmbJB42aWwSpHHmH64wJ2h'}\n",
      "Message ID run-bfc26e31-2a3d-4b7b-ba4e-194aad3e9787-0\n",
      "\n",
      "\n",
      "Tool calls\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'name': 'tavily_search_results_json',\n",
       "  'args': {'query': 'LangGraph human-in-the-loop workflow'},\n",
       "  'id': 'toolu_01KmbJB42aWwSpHHmH64wJ2h'}]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage\n",
    "\n",
    "snapshot = graph.get_state(config)\n",
    "existing_message = snapshot.values[\"messages\"][-1]\n",
    "print(\"Original\")\n",
    "print(existing_message.tool_calls[0])\n",
    "new_tool_call = existing_message.tool_calls[0].copy()\n",
    "new_tool_call[\"args\"][\"query\"] = \"LangGraph human-in-the-loop workflow\"\n",
    "new_message = AIMessage(\n",
    "    content=existing_message.content,\n",
    "    tool_calls=[new_tool_call],\n",
    "    # Important! The ID is how LangGraph knows to REPLACE the message in the state rather than APPEND this messages\n",
    "    id=existing_message.id,\n",
    ")\n",
    "\n",
    "print(\"Updated\")\n",
    "print(new_message.tool_calls[0])\n",
    "print(\"Message ID\", new_message.id)\n",
    "graph.update_state(config, {\"messages\": [new_message]})\n",
    "\n",
    "print(\"\\n\\nTool calls\")\n",
    "graph.get_state(config).values[\"messages\"][-1].tool_calls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "680f0ebd-ebce-4de6-8a9b-37d3d4ef0234",
   "metadata": {},
   "source": [
    "**Notice** that we've modified the AI's tool invocation to search for \"LangGraph persistance tutorial\" instead of the simple \"LangGraph\".\n",
    "\n",
    "Resume the graph by streaming with an input of `None` and the existing config."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "03a09bfc-3d90-4e54-878f-22e3cb28a418",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant: [{\"url\": \"https://langchain-ai.github.io/langgraph/how-tos/human-in-the-loop/\", \"content\": \"Human-in-the-loop\\u00b6 When creating LangGraph agents, it is often nice to add a human in the loop component. This can be helpful when giving them access to tools. ... from langgraph.graph import MessageGraph, END # Define a new graph workflow = MessageGraph # Define the two nodes we will cycle between workflow. add_node (\\\"agent\\\", call_model) ...\"}, {\"url\": \"https://langchain-ai.github.io/langgraph/how-tos/chat_agent_executor_with_function_calling/human-in-the-loop/\", \"content\": \"from langgraph.graph import StateGraph, END # Define a new graph workflow = StateGraph (AgentState) # Define the two nodes we will cycle between workflow. add_node (\\\"agent\\\", call_model) workflow. add_node (\\\"action\\\", call_tool) # Set the entrypoint as `agent` # This means that this node is the first one called workflow. set_entry_point (\\\"agent ...\"}]\n",
      "Assistant: Based on the additional search results, here's a more detailed overview of what LangGraph is and how it works:\n",
      "\n",
      "- LangGraph is a library built on top of LangChain that allows for the creation of more complex, multi-agent language models and applications.\n",
      "- The key features of LangGraph include:\n",
      "  - Ability to coordinate multiple \"chains\" or \"actors\" across multiple steps of computation in a cyclic manner.\n",
      "  - Support for building stateful, multi-actor applications using large language models (LLMs).\n",
      "  - Extensions to the LangChain Expression Language to enable this more advanced functionality.\n",
      "- LangGraph enables the creation of \"MessageGraphs\" and \"StateGraphs\" that define the flow of conversation and interaction between different agents/actors.\n",
      "- It includes support for \"human-in-the-loop\" workflows, where a human user can be integrated into the application to provide input, feedback, or take actions.\n",
      "- The library seems focused on enabling more sophisticated conversational and task-oriented applications that go beyond basic question answering or completion.\n",
      "\n",
      "Overall, LangGraph appears to be a powerful tool for building complex, multi-agent language systems that can engage in more nuanced and interactive dialogues. Let me know if you need any clarification or have additional questions!\n"
     ]
    }
   ],
   "source": [
    "events = graph.stream(None, config)\n",
    "for event in events:\n",
    "    for value in event.values():\n",
    "        if isinstance(value[\"messages\"][-1], BaseMessage):\n",
    "            print(\"Assistant:\", value[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "090b680b-f53f-4af2-a432-45f8c5a10779",
   "metadata": {},
   "source": [
    "**Notice** that now the first result of the search engine is the value about \"human-in-the-loop\" workflows in particular - we were able to manually override the LLM's search here.\n",
    "\n",
    "All of this is reflected in the graph's checkpointed memory, meaning if we continue the conversation, it will recall all the _modified_ state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "11d5b934-6d8b-4f52-a3bc-b3daa7207e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "events = graph.stream(\n",
    "    {\"messages\": (\"user\", \"Guess what I'm learning about these days?\")}, config\n",
    ")\n",
    "for event in events:\n",
    "    for value in event.values():\n",
    "        if isinstance(value, BaseMessage):\n",
    "            print(\"Assistant:\", value.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5166e1b-96a6-4ac0-88a1-bf32a422134a",
   "metadata": {},
   "source": [
    "**Congratulations!** You've used `interrupt_before` and `update_state` to manually modify the state as a part of a human-in-the-loop workflow. Interruptions and state modifications let you control how the agent behaves. Combined with persistant checkpointing, it means you can `pause` an action and `resume` at any point. Your user doesn't have to be available when the graph interrupts!\n",
    "\n",
    "The graph code for this section is identical to previous ones. The key snippets to remember are to add `.compile(..., interrupt_before=[...])` (or `interrupt_after`) if you want to explicitly pause the graph whenever it reaches a node. Then you can use `update_state` to modify the checkpoint and control how the graph should proceed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d88d4c9e-65c8-4093-a6c2-c261475f7c07",
   "metadata": {},
   "source": [
    "## Part 6: Customizing State\n",
    "\n",
    "So far, we've relied on a simple state (it's just a list of messages!). You can go far with this simple state, but if you want to define complex behavior without relying on the message list, you can add additional fields to the state. In this section, we will extend our chat bot with a new node to illustrate this.\n",
    "\n",
    "In the examples above, we involved a human deterministically: the graph __always__ interrupted whenever an tool was invoked. Suppose we wanted our chat bot to have the choice of relying on a human.\n",
    "\n",
    "One way to do this is to create a passthrough \"human\" node, before which the graph will always stop. We will only execute this node if the LLM invokes a \"human\" tool. For our convenience, we will include an \"ask_human\" flag in our graph state that we will flip if the LLM calls this tool.\n",
    "\n",
    "Below, define this new graph, with an updated `State`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "3cf7e042-1718-4625-ae30-a9917f595449",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated, Union\n",
    "\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_core.messages import BaseMessage\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "from langgraph.graph import MessageGraph, StateGraph\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt import ToolNode\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "    # This flag is new\n",
    "    ask_human: bool"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e87f2cb8-c066-4b54-acc4-e8c7399c5f3d",
   "metadata": {},
   "source": [
    "Next, define a schema to show the model to let it decide to request assistance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "e5192e54-6a28-42fe-a8a7-62d45d61f994",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.pydantic_v1 import BaseModel\n",
    "\n",
    "\n",
    "class RequestAssistance(BaseModel):\n",
    "    \"\"\"Escalate the conversation to an expert. Use this if you are unable to assist directly or if the user requires support beyond your permissions.\n",
    "\n",
    "    To use this function, relay the user's 'request' so the expert can provide the right guidance.\n",
    "    \"\"\"\n",
    "\n",
    "    request: str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b19c61b-2087-463b-adf8-96dbc193f41c",
   "metadata": {},
   "source": [
    "Next, define the chatbot node. The primary modification here is flip the `ask_human` flag if we see that the chat bot has invoked the `RequestAssistance` flag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "fa59b266-14e5-4c75-8b3d-54fac28e8290",
   "metadata": {},
   "outputs": [],
   "source": [
    "tool = TavilySearchResults(max_results=2)\n",
    "tools = [tool]\n",
    "llm = ChatAnthropic(model=\"claude-3-haiku-20240307\")\n",
    "# We can bind the llm to a tool definition, a pydantic model, or a json schema\n",
    "llm_with_tools = llm.bind_tools(tools + [RequestAssistance])\n",
    "\n",
    "\n",
    "def chatbot(state: State):\n",
    "    response = llm_with_tools.invoke(state[\"messages\"])\n",
    "    ask_human = False\n",
    "    if (\n",
    "        response.tool_calls\n",
    "        and response.tool_calls[0][\"name\"] == RequestAssistance.__name__\n",
    "    ):\n",
    "        ask_human = True\n",
    "    return {\"messages\": [response], \"ask_human\": ask_human}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ca0f57-2519-49c2-9499-888b5a884897",
   "metadata": {},
   "source": [
    "Next, create the graph builder and add the chatbot and tools nodes to the graph, same as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "3f4464d2-288b-4689-aaf0-329a55dcb85c",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_builder = StateGraph(State)\n",
    "\n",
    "graph_builder.add_node(\"chatbot\", chatbot)\n",
    "graph_builder.add_node(\"action\", ToolNode(tools=[tool]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f7a0ff3-b671-45c8-8157-ce5db411d370",
   "metadata": {},
   "source": [
    "Next, create the \"human\" `node`. This `node` function is mostly a placeholder in our graph that will trigger an interrupt. If the human does __not__ manually update the state during the `interrupt`, it inserts a tool message so the LLM knows the user was requested but didn't respond. This node also unsets the `ask_human` flag so the graph knows not to revisit the node unless further requests are made."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "1d70b5a4-ce50-47dc-aa43-ffb5c48c46fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_response(response: str, ai_message: AIMessage):\n",
    "    return ToolMessage(\n",
    "        content=response,\n",
    "        tool_call_id=ai_message.tool_calls[0][\"id\"],\n",
    "    )\n",
    "\n",
    "\n",
    "def human_node(state: State):\n",
    "    new_messages = []\n",
    "    if not isinstance(state[\"messages\"][-1], ToolMessage):\n",
    "        # Typically, the user will have updated the state during the interrupt.\n",
    "        # If they choose not to, we will include a placeholder ToolMessage to\n",
    "        # let the LLM continue.\n",
    "        new_messages.append(\n",
    "            create_response(\"No response from human.\", state[\"messages\"][-1])\n",
    "        )\n",
    "    return {\n",
    "        # Append the new messages\n",
    "        \"messages\": new_messages,\n",
    "        # Unset the flag\n",
    "        \"ask_human\": False,\n",
    "    }\n",
    "\n",
    "\n",
    "graph_builder.add_node(\"human\", human_node)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d56e5c65-f7b7-48bd-b0b5-fc8e590eca7d",
   "metadata": {},
   "source": [
    "Next, define the conditional logic. The `select_next_node` will route to the `human` node if the flag is set. Otherwise, it lets the prebuilt `tools_condition` function choose the next node.\n",
    "\n",
    "Recall that the `tools_condition` function simply checks to see if the `chatbot` has responded with any `tool_calls` in its response message. If so, it routes to the `action` node. Otherwise, it ends the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "586a0d07-8303-47f4-b3cf-3bdd043e762b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_next_node(state: State):\n",
    "    if state[\"ask_human\"]:\n",
    "        return \"human\"\n",
    "    # Otherwise, we can route as before\n",
    "    return tools_condition(state)\n",
    "\n",
    "\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"chatbot\",\n",
    "    select_next_node,\n",
    "    {\"human\": \"human\", \"action\": \"action\", \"__end__\": \"__end__\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66cd0bb1-b13e-477e-a08a-a7e657e2c19e",
   "metadata": {},
   "source": [
    "Finally, add the simple directed edges and compile the graph. These edges instruct the graph to **always** flow from node `a`->`b` whenever `a` finishes executing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "84101737-0048-4635-9f68-45b0c508b6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The rest is the same\n",
    "graph_builder.add_edge(\"action\", \"chatbot\")\n",
    "graph_builder.add_edge(\"human\", \"chatbot\")\n",
    "graph_builder.set_entry_point(\"chatbot\")\n",
    "memory = SqliteSaver.from_conn_string(\":memory:\")\n",
    "graph = graph_builder.compile(\n",
    "    checkpointer=memory,\n",
    "    # We interupt before 'human' here instead.\n",
    "    interrupt_before=[\"human\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f855593-8690-4a18-9ef8-7f3ccdc335bf",
   "metadata": {},
   "source": [
    "If you have the visualization dependencies installed, you can see the graph structure below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "b3220ae2-cba0-4447-96d1-eb0be4684e59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "try:\n",
    "    display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "except:\n",
    "    # This requires some extra dependencies and is optional\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b73851-810e-4466-89d8-37fba87e8494",
   "metadata": {},
   "source": [
    "The chat bot can either request help from a human (chatbot->select->human), invoke the search engine tool (chatbot->select->action), or directly respond (chatbot->select->__end__). Once an action or request has been made, the graph will transition back to the `chatbot` node to continue operations.\n",
    "\n",
    "Let's see this graph in action. We will request for expert assistance to illustrate our graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "c1955d79-a1e4-47d0-ba79-b45bd5752a23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant: [{'id': 'toolu_01L3hWS9SgXRniib6KPZ8Wpi', 'input': {'request': 'I need some expert guidance for building this AI agent.'}, 'name': 'RequestAssistance', 'type': 'tool_use'}]\n"
     ]
    }
   ],
   "source": [
    "user_input = \"I need some expert guidance for building this AI agent. Could you request assistance for me?\"\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "# The config is the **second positional argument** to stream() or invoke()!\n",
    "events = graph.stream({\"messages\": [(\"user\", user_input)]}, config)\n",
    "for event in events:\n",
    "    for value in event.values():\n",
    "        if isinstance(value[\"messages\"][-1], BaseMessage):\n",
    "            print(\"Assistant:\", value[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3945ea4-8dbd-4e14-ae2a-34da7f05a0c1",
   "metadata": {},
   "source": [
    "**Notice:** the LLM has invoked the \"`RequestAssistance`\" tool we provided it, and the interrupt has been set. Let's inspect the graph state to confirm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "5320ba05-5696-4194-8278-5385c571264d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('human',)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snapshot = graph.get_state(config)\n",
    "snapshot.next"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed2dd02e-f0a6-4f63-a7d6-e49ecf40db21",
   "metadata": {},
   "source": [
    "The graph state is indeed **interrupted** before the `'human'` node. We can act as the \"expert\" in this scenario and manually update the state by adding a new ToolMessage with our input.\n",
    "\n",
    "Next, respond to the chatbot's request by:\n",
    "1. Creating a `ToolMessage` with our response. This will be passed back to the `chatbot`.\n",
    "2. Calling `update_state` to manually update the graph state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "2cbac924-61ce-4282-9b1c-77f9090ea1f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'configurable': {'thread_id': '1',\n",
       "  'thread_ts': '2024-04-18T01:36:13.347820+00:00'}}"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ai_message = snapshot.values[\"messages\"][-1]\n",
    "human_response = (\n",
    "    \"We, the experts are here to help! We'd recommend you check out LangGraph to build your agent.\"\n",
    "    \" It's much more reliable and extensible than simple autonomous agents.\"\n",
    ")\n",
    "tool_message = create_response(human_response, ai_message)\n",
    "graph.update_state(config, {\"messages\": [tool_message]})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79492363-7fc6-4ec7-977d-9030648029bc",
   "metadata": {},
   "source": [
    "You can inspect the state to confirm our response was added."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "4b986c66-1c65-4da8-a404-db7e28f8364e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='I need some expert guidance for building this AI agent. Could you request assistance for me?', id='bfcbc7bb-1c42-414e-b8c3-7df56e613d57'),\n",
       " AIMessage(content=[{'id': 'toolu_01L3hWS9SgXRniib6KPZ8Wpi', 'input': {'request': 'I need some expert guidance for building this AI agent.'}, 'name': 'RequestAssistance', 'type': 'tool_use'}], response_metadata={'id': 'msg_01JuYz1TvVVSGKc5v9s8RN7N', 'model': 'claude-3-haiku-20240307', 'stop_reason': 'tool_use', 'stop_sequence': None, 'usage': {'input_tokens': 486, 'output_tokens': 63}}, id='run-07a89b06-7600-41bb-81fc-f23f08fe206c-0', tool_calls=[{'name': 'RequestAssistance', 'args': {'request': 'I need some expert guidance for building this AI agent.'}, 'id': 'toolu_01L3hWS9SgXRniib6KPZ8Wpi'}]),\n",
       " ToolMessage(content=\"We, the experts are here to help! We'd recommend you check out LangGraph to build your agent. It's much more reliable and extensible than simple autonomous agents.\", id='db980d20-aff4-435b-8be4-9b275f7015d6', tool_call_id='toolu_01L3hWS9SgXRniib6KPZ8Wpi')]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.get_state(config).values[\"messages\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea6b8616-de10-44d6-a8f0-3ac73c3c3680",
   "metadata": {},
   "source": [
    "Next, **resume** the graph by invoking it with `None` as the inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "6b32914d-4d60-491f-8e11-1e6867e38ffd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant: Based on your request, I've escalated it to our team of experts to provide guidance on building your AI agent. The experts have recommended using LangGraph, which they say is a more reliable and extensible solution compared to simple autonomous agents. Please let me know if you have any other questions - I'm happy to assist further or connect you directly with the expert team.\n"
     ]
    }
   ],
   "source": [
    "events = graph.stream(None, config)\n",
    "for event in events:\n",
    "    for value in event.values():\n",
    "        if value[\"messages\"] and isinstance(value[\"messages\"][-1], BaseMessage):\n",
    "            print(\"Assistant:\", value[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48e0559b-d653-4dab-8928-b001004d14cb",
   "metadata": {},
   "source": [
    "**Notice** that the chat bot has incorporated the updated state in its final response. Since **everything** was checkpointed, the \"expert\" human in the loop could perform the update at any time without impacting the graph's execution.\n",
    "\n",
    "**Congratulations!** you've now added an additional node to your assistant graph to let the chat bot decide for itself whether or not it needs to interrupt execution. You did so by updating the graph `State` with a new `ask_human` field and modifying the interruption logic when compiling the graph. This lets you dynamically include a human in the loop while maintaining full **memory** every time you execute the graph.\n",
    "\n",
    "We're almost done with the tutorial, but there is one more concept we'd like to review before finishing that connects `checkpointing` and `state updates`. \n",
    "\n",
    "This section's code is reproduced below for your reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "6516baf8-bbb6-4400-b867-0add1a087342",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated, Union\n",
    "\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_core.messages import BaseMessage\n",
    "from langchain_core.pydantic_v1 import BaseModel\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "from langgraph.graph import MessageGraph, StateGraph\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt import ToolNode\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "    # This flag is new\n",
    "    ask_human: bool\n",
    "\n",
    "\n",
    "class RequestAssistance(BaseModel):\n",
    "    \"\"\"Escalate the conversation to an expert. Use this if you are unable to assist directly or if the user requires support beyond your permissions.\n",
    "\n",
    "    To use this function, relay the user's 'request' so the expert can provide the right guidance.\n",
    "    \"\"\"\n",
    "\n",
    "    request: str\n",
    "\n",
    "\n",
    "tool = TavilySearchResults(max_results=2)\n",
    "tools = [tool]\n",
    "llm = ChatAnthropic(model=\"claude-3-haiku-20240307\")\n",
    "# We can bind the llm to a tool definition, a pydantic model, or a json schema\n",
    "llm_with_tools = llm.bind_tools(tools + [RequestAssistance])\n",
    "\n",
    "\n",
    "def chatbot(state: State):\n",
    "    response = llm_with_tools.invoke(state[\"messages\"])\n",
    "    ask_human = False\n",
    "    if (\n",
    "        response.tool_calls\n",
    "        and response.tool_calls[0][\"name\"] == RequestAssistance.__name__\n",
    "    ):\n",
    "        ask_human = True\n",
    "    return {\"messages\": [response], \"ask_human\": ask_human}\n",
    "\n",
    "\n",
    "graph_builder = StateGraph(State)\n",
    "\n",
    "graph_builder.add_node(\"chatbot\", chatbot)\n",
    "graph_builder.add_node(\"action\", ToolNode(tools=[tool]))\n",
    "\n",
    "\n",
    "def create_response(response: str, ai_message: AIMessage):\n",
    "    return ToolMessage(\n",
    "        content=response,\n",
    "        tool_call_id=ai_message.tool_calls[0][\"id\"],\n",
    "    )\n",
    "\n",
    "\n",
    "def human_node(state: State):\n",
    "    new_messages = []\n",
    "    if not isinstance(state[\"messages\"][-1], ToolMessage):\n",
    "        # Typically, the user will have updated the state during the interrupt.\n",
    "        # If they choose not to, we will include a placeholder ToolMessage to\n",
    "        # let the LLM continue.\n",
    "        new_messages.append(\n",
    "            create_response(\"No response from human.\", state[\"messages\"][-1])\n",
    "        )\n",
    "    return {\n",
    "        # Append the new messages\n",
    "        \"messages\": new_messages,\n",
    "        # Unset the flag\n",
    "        \"ask_human\": False,\n",
    "    }\n",
    "\n",
    "\n",
    "graph_builder.add_node(\"human\", human_node)\n",
    "\n",
    "\n",
    "def select_next_node(state: State):\n",
    "    if state[\"ask_human\"]:\n",
    "        return \"human\"\n",
    "    # Otherwise, we can route as before\n",
    "    return tools_condition(state)\n",
    "\n",
    "\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"chatbot\",\n",
    "    select_next_node,\n",
    "    {\"human\": \"human\", \"action\": \"action\", \"__end__\": \"__end__\"},\n",
    ")\n",
    "graph_builder.add_edge(\"action\", \"chatbot\")\n",
    "graph_builder.add_edge(\"human\", \"chatbot\")\n",
    "graph_builder.set_entry_point(\"chatbot\")\n",
    "memory = SqliteSaver.from_conn_string(\":memory:\")\n",
    "graph = graph_builder.compile(\n",
    "    checkpointer=memory,\n",
    "    interrupt_before=[\"human\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05283db2-2f26-4800-8eda-78a4468a3d8f",
   "metadata": {},
   "source": [
    "## Part 7: Time Travel\n",
    "\n",
    "In a typical chat bot workflow, the user interacts with the bot 1 or more times to accomplish a task. In the previous sections, we saw how to add memory and a human-in-the-loop to be able to checkpoint our graph state and manually override the state to control future responses.\n",
    "\n",
    "But what if you want to let your user start from a previous response and \"branch off\" to explore a separate outcome? Or what if you want users to be able to \"rewind\" your assistant's work to fix some mistakes or try a different strategy (common in applications like autonomous software engineers)?\n",
    "\n",
    "You can create both of these experiences and more using LangGraph's built-in \"time travel\" functionality. \n",
    "\n",
    "In this section, you will \"rewind\" your graph by fetching a checkpoint using the graph's `get_state_history` method. You can then resume execution at this previous point in time.\n",
    "\n",
    "First, recall our chatbot graph. We don't need to make **any** changes from before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "bb8a02de-a21b-4ef6-a714-7d6e44435e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated, Union\n",
    "\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_core.messages import BaseMessage\n",
    "from langchain_core.pydantic_v1 import BaseModel\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "from langgraph.graph import MessageGraph, StateGraph\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt import ToolNode\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "    # This flag is new\n",
    "    ask_human: bool\n",
    "\n",
    "\n",
    "class RequestAssistance(BaseModel):\n",
    "    \"\"\"Escalate the conversation to an expert. Use this if you are unable to assist directly or if the user requires support beyond your permissions.\n",
    "\n",
    "    To use this function, relay the user's 'request' so the expert can provide the right guidance.\n",
    "    \"\"\"\n",
    "\n",
    "    request: str\n",
    "\n",
    "\n",
    "tool = TavilySearchResults(max_results=2)\n",
    "tools = [tool]\n",
    "llm = ChatAnthropic(model=\"claude-3-haiku-20240307\")\n",
    "# We can bind the llm to a tool definition, a pydantic model, or a json schema\n",
    "llm_with_tools = llm.bind_tools(tools + [RequestAssistance])\n",
    "\n",
    "\n",
    "def chatbot(state: State):\n",
    "    response = llm_with_tools.invoke(state[\"messages\"])\n",
    "    ask_human = False\n",
    "    if (\n",
    "        response.tool_calls\n",
    "        and response.tool_calls[0][\"name\"] == RequestAssistance.__name__\n",
    "    ):\n",
    "        ask_human = True\n",
    "    return {\"messages\": [response], \"ask_human\": ask_human}\n",
    "\n",
    "\n",
    "graph_builder = StateGraph(State)\n",
    "\n",
    "graph_builder.add_node(\"chatbot\", chatbot)\n",
    "graph_builder.add_node(\"action\", ToolNode(tools=[tool]))\n",
    "\n",
    "\n",
    "def create_response(response: str, ai_message: AIMessage):\n",
    "    return ToolMessage(\n",
    "        content=response,\n",
    "        tool_call_id=ai_message.tool_calls[0][\"id\"],\n",
    "    )\n",
    "\n",
    "\n",
    "def human_node(state: State):\n",
    "    new_messages = []\n",
    "    if not isinstance(state[\"messages\"][-1], ToolMessage):\n",
    "        # Typically, the user will have updated the state during the interrupt.\n",
    "        # If they choose not to, we will include a placeholder ToolMessage to\n",
    "        # let the LLM continue.\n",
    "        new_messages.append(\n",
    "            create_response(\"No response from human.\", state[\"messages\"][-1])\n",
    "        )\n",
    "    return {\n",
    "        # Append the new messages\n",
    "        \"messages\": new_messages,\n",
    "        # Unset the flag\n",
    "        \"ask_human\": False,\n",
    "    }\n",
    "\n",
    "\n",
    "graph_builder.add_node(\"human\", human_node)\n",
    "\n",
    "\n",
    "def select_next_node(state: State):\n",
    "    if state[\"ask_human\"]:\n",
    "        return \"human\"\n",
    "    # Otherwise, we can route as before\n",
    "    return tools_condition(state)\n",
    "\n",
    "\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"chatbot\",\n",
    "    select_next_node,\n",
    "    {\"human\": \"human\", \"action\": \"action\", \"__end__\": \"__end__\"},\n",
    ")\n",
    "graph_builder.add_edge(\"action\", \"chatbot\")\n",
    "graph_builder.add_edge(\"human\", \"chatbot\")\n",
    "graph_builder.set_entry_point(\"chatbot\")\n",
    "memory = SqliteSaver.from_conn_string(\":memory:\")\n",
    "graph = graph_builder.compile(\n",
    "    checkpointer=memory,\n",
    "    interrupt_before=[\"human\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5414c482-215e-4cc0-9eef-4a8722d2f468",
   "metadata": {},
   "source": [
    "Let's have our graph take a couple steps. Every step will be checkpointed in its state history:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "69071b02-c011-4b7f-90b1-8e89e032322d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant: [{'text': 'Certainly, let me look into LangGraph for you:', 'type': 'text'}, {'id': 'toolu_01PeLhJCgjKjFKegvH8AN5mj', 'input': {'query': 'LangGraph'}, 'name': 'tavily_search_results_json', 'type': 'tool_use'}]\n",
      "Assistant: [{\"url\": \"https://python.langchain.com/docs/langgraph/\", \"content\": \"LangGraph is a library for building stateful, multi-actor applications with LLMs, built on top of (and intended to be used with) LangChain . It extends the LangChain Expression Language with the ability to coordinate multiple chains (or actors) across multiple steps of computation in a cyclic manner. It is inspired by Pregel and Apache Beam .\"}, {\"url\": \"https://blog.langchain.dev/langgraph/\", \"content\": \"Some of the things we are looking to implement in the near future:\\nIf any of these resonate with you, please feel free to add an example notebook in the LangGraph repo, or reach out to us at hello@langchain.dev for more involved collaboration!\\n See this notebook for how to get started\\nModifications\\nOne of the big benefits of LangGraph is that it exposes the logic of AgentExecutor in a far more natural and modifiable way. An example of this could be that after a model is called we either exit the graph and return to the user, or we call a tool - depending on what a user decides! This function/LCEL should accept a dictionary in the same form as the State object as input, and output a dictionary with keys of the State object to update.\\n In this case, it's often ideal if the LLM can reason that the results returned from the retriever are poor, and maybe issue a second (more refined) query to the retriever, and use those results instead.\"}]\n",
      "Assistant: Based on the search results, LangGraph seems to be a library built on top of LangChain that allows for building more complex, stateful, multi-actor applications using large language models (LLMs). Some key points:\n",
      "\n",
      "- LangGraph extends the LangChain Expression Language (LCEL) to coordinate multiple \"chains\" or \"actors\" across multiple steps of computation in a cyclic manner.\n",
      "- It is inspired by distributed graph processing frameworks like Pregel and Apache Beam.\n",
      "- Some key features they are working on include more flexible modifications to the agent execution flow and the ability to refine retriever queries based on the results.\n",
      "- The library is intended to make it easier to build more advanced, stateful applications using LLMs compared to the standard LangChain approach.\n",
      "\n",
      "Let me know if you need any clarification or have additional questions about LangGraph! I'm happy to provide more details.\n"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "events = graph.stream(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            (\"user\", \"I'm learning LangGraph. Could you do some research on it for me?\")\n",
    "        ]\n",
    "    },\n",
    "    config,\n",
    ")\n",
    "for event in events:\n",
    "    for value in event.values():\n",
    "        if isinstance(value[\"messages\"][-1], BaseMessage):\n",
    "            print(\"Assistant:\", value[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "acbec099-e5d2-497f-929e-c548d7bcbf77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant: [{'text': \"That's great that you're interested in building an autonomous agent using LangGraph! It seems like a powerful tool for creating more complex, multi-step applications with language models.\\n\\nA few thoughts on building an autonomous agent with LangGraph:\", 'type': 'text'}, {'id': 'toolu_01Sc4kLituPFJ2FGuM8M4iBF', 'input': {'query': 'building autonomous agents with langgraph'}, 'name': 'tavily_search_results_json', 'type': 'tool_use'}]\n",
      "Assistant: [{\"url\": \"https://blog.langchain.dev/langgraph-multi-agent-workflows/\", \"content\": \"As a part of the launch, we highlighted two simple runtimes: one that is the equivalent of the AgentExecutor in langchain, and a second that was a version of that aimed at message passing and chat models.\\n It's important to note that these three examples are only a few of the possible examples we could highlight - there are almost assuredly other examples out there and we look forward to seeing what the community comes up with!\\n LangGraph: Multi-Agent Workflows\\nLinks\\nLast week we highlighted LangGraph - a new package (available in both Python and JS) to better enable creation of LLM workflows containing cycles, which are a critical component of most agent runtimes. \\\"\\nAnother key difference between Autogen and LangGraph is that LangGraph is fully integrated into the LangChain ecosystem, meaning you take fully advantage of all the LangChain integrations and LangSmith observability.\\n As part of this launch, we're also excited to highlight a few applications built on top of LangGraph that utilize the concept of multiple agents.\\n\"}, {\"url\": \"https://valentinaalto.medium.com/getting-started-with-langgraph-66388e023754\", \"content\": \"Sign up\\nSign in\\nSign up\\nSign in\\nMember-only story\\nGetting Started with LangGraph\\nBuilding multi-agents application with graph frameworks\\nValentina Alto\\nFollow\\n--\\nShare\\nOver the last year, LangChain has established itself as one of the most popular AI framework available in the market. This new library, introduced in January\\u2026\\n--\\n--\\nWritten by Valentina Alto\\nData&AI Specialist at @Microsoft | MSc in Data Science | AI, Machine Learning and Running enthusiast\\nHelp\\nStatus\\nAbout\\nCareers\\nBlog\\nPrivacy\\nTerms\\nText to speech\\nTeams Since the concept of multi-agent applications \\u2014 the ones exhibiting different agents, each having a specific personality and tools to access \\u2014 is getting real and mainstream (see the rise of libraries projects like AutoGen), LangChain\\u2019s developers introduced a new library to make it easier to manage these kind of agentic applications. Nevertheless, those chains were lacking the capability of introducing cycles into their runtime, meaning that there is no out-of-the-box framework to enable the LLM to reason over the next best action in a kind of for-loop scenario. The main feature of LangChain \\u2014 as the name suggests \\u2014 is its ability to easily create the so-called chains.\"}]\n",
      "Assistant: The search results indicate that LangGraph was specifically designed to enable the creation of more complex, multi-agent workflows and applications. Some key points:\n",
      "\n",
      "- LangGraph extends LangChain to better handle cyclic computations and back-and-forth flows, which are critical for building autonomous agents.\n",
      "- It provides runtimes specifically designed for message passing and chat models, which could be very relevant for an autonomous agent application.\n",
      "- LangGraph is integrated with the broader LangChain ecosystem, allowing you to leverage all the existing integrations and tooling.\n",
      "- The blog posts highlight examples of multi-agent applications built on top of LangGraph, which could provide a good starting point for your own autonomous agent project.\n",
      "\n",
      "I'd recommend reviewing those blog posts and example notebooks to get a better sense of how to structure your autonomous agent using LangGraph. Feel free to let me know if you have any other specific questions as you start building it out!\n"
     ]
    }
   ],
   "source": [
    "events = graph.stream(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            (\"user\", \"Ya that's helpful. Maybe I'll build an autonomous agent with it!\")\n",
    "        ]\n",
    "    },\n",
    "    config,\n",
    ")\n",
    "for event in events:\n",
    "    for value in event.values():\n",
    "        if isinstance(value[\"messages\"][-1], BaseMessage):\n",
    "            print(\"Assistant:\", value[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e48c77-65f3-4075-8030-ebf943a281f1",
   "metadata": {},
   "source": [
    "Now that we've had the agent take a couple steps, we can `replay` the full state history to see everything that occurred."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "6c0dbed5-210d-40ad-b002-0bc52ef28fac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Messages:  8 Next:  ()\n",
      "--------------------------------------------------------------------------------\n",
      "Num Messages:  7 Next:  ('chatbot',)\n",
      "--------------------------------------------------------------------------------\n",
      "Num Messages:  6 Next:  ('action',)\n",
      "--------------------------------------------------------------------------------\n",
      "Num Messages:  5 Next:  ('chatbot',)\n",
      "--------------------------------------------------------------------------------\n",
      "Num Messages:  4 Next:  ()\n",
      "--------------------------------------------------------------------------------\n",
      "Num Messages:  3 Next:  ('chatbot',)\n",
      "--------------------------------------------------------------------------------\n",
      "Num Messages:  2 Next:  ('action',)\n",
      "--------------------------------------------------------------------------------\n",
      "Num Messages:  1 Next:  ('chatbot',)\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "to_replay = None\n",
    "for state in graph.get_state_history(config):\n",
    "    print(\"Num Messages: \", len(state.values[\"messages\"]), \"Next: \", state.next)\n",
    "    print(\"-\" * 80)\n",
    "    if len(state.values[\"messages\"]) == 6:\n",
    "        # We are somewhat arbitrarily selecting a specific state based on the number of chat messages in the state.\n",
    "        to_replay = state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b182019e-bae3-4616-ba1b-f845c0ab6636",
   "metadata": {},
   "source": [
    "**Notice** that checkpoints are saved for every step of the graph. This _spans invocations__ so you can rewind across a full thread's history. We've picked out `to_replay` as a state to resume from. This is the state after the `chatbot` node in the second graph invocation above.\n",
    "\n",
    "Resuming from this point should call the **action** node next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "de8d5521-8d71-4093-a657-4920c790802f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('action',)\n",
      "{'configurable': {'thread_id': '1', 'thread_ts': '2024-04-18T01:54:15.721809+00:00'}}\n"
     ]
    }
   ],
   "source": [
    "print(to_replay.next)\n",
    "print(to_replay.config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e8c61f5-3a4a-4cce-b81b-43fe1dcc971f",
   "metadata": {},
   "source": [
    "**Notice** that the checkpoint's config (`to_replay.config`) contains a `thread_ts` **timestamp**. Providing this `thread_ts` value tells LangGraph's checkpointer to **load** the state from that moment in time. Let's try it below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "85f17be3-eaf6-495e-a846-49436916b4ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant: [{\"url\": \"https://blog.langchain.dev/langgraph-multi-agent-workflows/\", \"content\": \"As a part of the launch, we highlighted two simple runtimes: one that is the equivalent of the AgentExecutor in langchain, and a second that was a version of that aimed at message passing and chat models.\\n It's important to note that these three examples are only a few of the possible examples we could highlight - there are almost assuredly other examples out there and we look forward to seeing what the community comes up with!\\n LangGraph: Multi-Agent Workflows\\nLinks\\nLast week we highlighted LangGraph - a new package (available in both Python and JS) to better enable creation of LLM workflows containing cycles, which are a critical component of most agent runtimes. \\\"\\nAnother key difference between Autogen and LangGraph is that LangGraph is fully integrated into the LangChain ecosystem, meaning you take fully advantage of all the LangChain integrations and LangSmith observability.\\n As part of this launch, we're also excited to highlight a few applications built on top of LangGraph that utilize the concept of multiple agents.\\n\"}, {\"url\": \"https://valentinaalto.medium.com/getting-started-with-langgraph-66388e023754\", \"content\": \"Sign up\\nSign in\\nSign up\\nSign in\\nMember-only story\\nGetting Started with LangGraph\\nBuilding multi-agents application with graph frameworks\\nValentina Alto\\nFollow\\n--\\nShare\\nOver the last year, LangChain has established itself as one of the most popular AI framework available in the market. This new library, introduced in January\\u2026\\n--\\n--\\nWritten by Valentina Alto\\nData&AI Specialist at @Microsoft | MSc in Data Science | AI, Machine Learning and Running enthusiast\\nHelp\\nStatus\\nAbout\\nCareers\\nBlog\\nPrivacy\\nTerms\\nText to speech\\nTeams Since the concept of multi-agent applications \\u2014 the ones exhibiting different agents, each having a specific personality and tools to access \\u2014 is getting real and mainstream (see the rise of libraries projects like AutoGen), LangChain\\u2019s developers introduced a new library to make it easier to manage these kind of agentic applications. Nevertheless, those chains were lacking the capability of introducing cycles into their runtime, meaning that there is no out-of-the-box framework to enable the LLM to reason over the next best action in a kind of for-loop scenario. The main feature of LangChain \\u2014 as the name suggests \\u2014 is its ability to easily create the so-called chains.\"}]\n",
      "Assistant: A few key things to consider:\n",
      "\n",
      "- LangGraph is designed to enable building multi-agent workflows and applications, which could be very applicable for an autonomous agent use case. The library helps coordinate multiple \"actors\" or \"chains\" in a cyclic manner.\n",
      "- One key advantage of LangGraph over standard LangChain is the ability to introduce cycles and more complex execution flows, rather than just linear chains. This could be useful for an autonomous agent that needs to reason about and refine its actions over multiple steps.\n",
      "- The blog post mentions LangGraph being integrated with LangChain, so you can leverage all the existing LangChain tools, integrations, and observability features.\n",
      "- There are some example workflows and applications highlighted in the blog posts that could give you ideas on how to structure an autonomous agent use case.\n",
      "\n",
      "I'd recommend taking a look at the LangGraph documentation and examples to get a better sense of how you might be able to use it to build your autonomous agent. Feel free to reach out if you have any other questions as you explore this!\n"
     ]
    }
   ],
   "source": [
    "# The `thread_ts` in the `to_replay.config` corresponds to a state we've persisted to our checkpointer.\n",
    "for event in graph.stream(None, to_replay.config):\n",
    "    for value in event.values():\n",
    "        if isinstance(value[\"messages\"][-1], BaseMessage):\n",
    "            print(\"Assistant:\", value[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2501fed-2591-420d-98e0-4a3836fb99a8",
   "metadata": {},
   "source": [
    "Notice that the graph resumed execution from the `**action**` node. You can tell this is the case since the first value printed above is the response from our search engine tool.\n",
    "\n",
    "**Congrats!** You've replayed your graph from a previous state using LangGraph's built-in \"time travel\" functionality. This lets your app natively branch from any previous state in its execution, enabling functionality like:\n",
    "\n",
    "- Recovery from a previous checkpoint if a long-running process enters a failure state.\n",
    "- Letting a user branch sessions off of previous one.\n",
    "- Letting an agent search a possible path, update the state, and try again from a previous checkpoint."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e584d57f-5aad-4507-815f-0b2e4b64b791",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Congrats! You've completed the intro tutorial and built a chat bot in LangGraph that supports tool calling, persistent memory, human-in-the-loop interactivity, and even time-travel!\n",
    "\n",
    "Check out some of the other examples in the LangGraph docs for more advanced use cases, and check out the how-tos for other examples on how to address frequently asked questions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
